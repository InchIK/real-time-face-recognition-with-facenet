{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import facenet\n",
    "import detect_face\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "from numpy import array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<facenet.ImageClass instance at 0x1a2563e440>, <facenet.ImageClass instance at 0x1a2563e2d8>, <facenet.ImageClass instance at 0x1a2563ed40>]\n",
      "Number of classes: 3\n",
      "Number of images: 50\n",
      "Loading feature extraction model\n",
      "Model filename: ./pre_model/20170511-185253.pb\n",
      "Calculating features for images\n",
      "(50, 128)\n",
      "(50,)\n",
      "(50, 3)\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "Training classifier\n",
      "Epoch 1/5\n",
      "50/50 [==============================] - 1s 30ms/step - loss: 1.0726 - acc: 0.5200\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 0s 284us/step - loss: 1.0248 - acc: 0.7600\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 0s 197us/step - loss: 0.9913 - acc: 0.8600\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 0s 239us/step - loss: 0.9618 - acc: 0.9200\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 0s 192us/step - loss: 0.9336 - acc: 0.9600\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        datadir = './out_dir'\n",
    "        dataset = facenet.get_dataset(datadir)\n",
    "        paths, labels = facenet.get_image_paths_and_labels(dataset)\n",
    "        print (dataset)\n",
    "        print('Number of classes: %d' % len(dataset))\n",
    "        print('Number of images: %d' % len(paths))\n",
    "\n",
    "        print('Loading feature extraction model')\n",
    "        modeldir = './pre_model/20170511-185253.pb'\n",
    "        facenet.load_model(modeldir)\n",
    "\n",
    "        images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "        embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "        phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "        embedding_size = embeddings.get_shape()[1]\n",
    "\n",
    "        # Run forward pass to calculate embeddings\n",
    "        print('Calculating features for images')\n",
    "        batch_size = 1000\n",
    "        image_size = 160\n",
    "        nrof_images = len(paths)\n",
    "        nrof_batches_per_epoch = int(math.ceil(1.0 * nrof_images / batch_size))\n",
    "        emb_array = np.zeros((nrof_images, embedding_size))\n",
    "        for i in range(nrof_batches_per_epoch):\n",
    "            start_index = i * batch_size\n",
    "            end_index = min((i + 1) * batch_size, nrof_images)\n",
    "            paths_batch = paths[start_index:end_index]\n",
    "            images = facenet.load_data(paths_batch, False, False, image_size)\n",
    "            feed_dict = {images_placeholder: images, phase_train_placeholder: False}\n",
    "            emb_array[start_index:end_index, :] = sess.run(embeddings, feed_dict=feed_dict)\n",
    "\n",
    "        classifier_filename = './my_class/my_classifier.pkl'\n",
    "        classifier_filename_exp = os.path.expanduser(classifier_filename)\n",
    "        label_array = array(labels)\n",
    "        print (emb_array.shape)\n",
    "#         print(labels)\n",
    "#         print(type(label_array))\n",
    "        print(label_array.shape)\n",
    "        one_hot_labels = keras.utils.to_categorical(label_array, num_classes=3)\n",
    "        print(one_hot_labels.shape)\n",
    "        print(one_hot_labels)\n",
    "        # Train classifier\n",
    "        print('Training classifier')\n",
    "        # model = SVC(kernel='sigmoid', probability=True)\n",
    "        # model.fit(emb_array, labels)\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, activation='relu', input_dim=128))\n",
    "        model.add(Dense(16, activation='relu'))\n",
    "        model.add(Dense(3, activation='softmax'))\n",
    "        model.compile(optimizer='rmsprop',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        model.fit(emb_array, one_hot_labels, epochs=5, batch_size=32)\n",
    "        model.save('my_model.h5')\n",
    "        \n",
    "        # Train the model, iterating on the data in batches of 32 s\n",
    "\n",
    "        # Create a list of class names\n",
    "        # class_names = [cls.name.replace('_', ' ') for cls in dataset]\n",
    "        #\n",
    "        # # Saving classifier model\n",
    "        # with open(classifier_filename_exp, 'wb') as outfile:\n",
    "        #     pickle.dump((model, class_names), outfile)\n",
    "        # print('Saved classifier model to file \"%s\"' % classifier_filename_exp)\n",
    "        # print('Goodluck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
